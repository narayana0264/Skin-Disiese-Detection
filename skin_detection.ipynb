{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install roboflow\n",
    "!pip install torch torchvision\n",
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/WongKinYiu/yolov9\n",
    "%cd yolov9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "weights_dir = \"/content/drive/MyDrive/yolov9_weights\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"CjO2MQmvyPJDsxvgneCq\")\n",
    "project = rf.workspace(\"my-project-xhvrg\").project(\"skin-disease-ges3o\")\n",
    "version = project.version(5)\n",
    "dataset = version.download(\"yolov9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {dataset.location}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOv9Custom(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(YOLOv9Custom, self).__init__()\n",
    "        # Insert YOLOv9 layers\n",
    "        # Modify by adding ReLU activation in appropriate layers\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        # Add more YOLOv9 layers here with ReLU\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        # Forward pass through other YOLOv9 layers\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLOv9Custom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = \"path/to/custom/weights.pt\"\n",
    "model.load_state_dict(torch.load(weights_path, map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yolov9.train import train\n",
    "\n",
    "# Configure the training settings\n",
    "train_cfg = {\n",
    "    'epochs': 50,\n",
    "    'batch_size': 16,\n",
    "    'data': f'{dataset.location}/data.yaml',\n",
    "    'weights': weights_path,  #custom weights\n",
    "    'save_dir': weights_dir,  # Save model weights in gdrive\n",
    "    'img_size': 640,\n",
    "    'optimizer': 'SGD',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(train_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'{weights_dir}/best_yolov9_weights.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yolov9.val import val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_cfg = {\n",
    "    'data': f'{dataset.location}/data.yaml',\n",
    "    'weights': f'{weights_dir}/best_yolov9_weights.pt',\n",
    "    'img_size': 640,\n",
    "}\n",
    "\n",
    "val(val_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert PyTorch model to TensorFlow .h5 format\n",
    "import tensorflow as tf\n",
    "\n",
    "# Save the trained PyTorch model as .h5 (simplified conversion)\n",
    "dummy_input = torch.randn(1, 3, 640, 640)  # A sample input shape\n",
    "torch.onnx.export(model, dummy_input, \"yolov9.onnx\")\n",
    "\n",
    "# Convert the ONNX model to TensorFlow format\n",
    "!pip install onnx onnx-tf\n",
    "import onnx\n",
    "from onnx_tf.backend import prepare\n",
    "\n",
    "onnx_model = onnx.load(\"yolov9.onnx\")\n",
    "tf_rep = prepare(onnx_model)\n",
    "tf_rep.export_graph(\"yolov9_model.h5\")\n",
    "\n",
    "# Save .h5 in Google Drive\n",
    "!mv yolov9_model.h5 /content/drive/MyDrive/yolov9_model.h5\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
